---
layout: post
title: Llama1-3ï¼šä»ä¸€é“ç¾å›¢å¤§æ¨¡å‹é¢è¯•é¢˜è®²èµ·ğŸ¦˜
date: 2025-01-09 20:25:53
categories:
    - ğŸ“– è®ºæ–‡é˜…è¯»
tags: [å¤§è¯­è¨€æ¨¡å‹, NLP, NLPç»å…¸è®ºæ–‡]
index_img: https://cdn.jsdelivr.net/gh/lazypool/blog-pics/animals/panda.png
---

# ä» LLaMA1 åˆ° LLaMA3ï¼šè¿™é£äº‘æ¿€è¡çš„ 2023 åˆ° 2024 å¹´

è¿™ç¯‡åšå®¢åº”å½“æ˜¯æˆ‘åœ¨ 2025 å¹´çš„é¦–ç¯‡åšå®¢ã€‚24 å¹´åº•ï¼Œåœ¨æˆ‘èº«ä¸Šå‘ç”Ÿäº†å¾ˆå¤šæ„æƒ³ä¸åˆ°çš„äº‹æƒ…ï¼Œæ€»ä½¿æˆ‘ç°å¿ƒä¸§æ°”ã€‚å¿½ç„¶é—´ï¼Œå‘è§‰è‡ªå·±é™¤å¼€å†™äº†åå‡ ä¸ªæœˆçš„æ—¥è®°ï¼Œå¹¶æ²¡æœ‰æ›´å¤šæ–°çš„æ›´æ–°ã€‚å‰ä¸ä¹…ï¼Œåœ¨ B ç«™ä¸Šçœ‹åˆ°åä¸º **ç¾å›¢å¤§æ¨¡å‹é¢è¯•çœŸé¢˜ï¼šLLaMAæ€ä¹ˆä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—ï¼Ÿ** çš„è§†é¢‘ï¼Œæˆ‘æ‰æƒŠè§‰æ—¶å…‰é£é€ã€‚

äºæ˜¯æƒ³ç€ï¼Œä¼¼ä¹åº”å½“å†™ä¸€ç¯‡è¯¦è§£ LLaMA çš„åšå®¢å‡ºæ¥ã€‚ç­‰åˆ°è°ƒæŸ¥èµ„æ–™çš„æ—¶å€™ï¼Œå‘ç° LLaMA åŸæ¥æ—©åœ¨ 2023 å¹´å°±å·²å‘å¸ƒï¼Œä¸”å·²åˆ°ç¬¬ä¸‰ä»£ã€‚ä¼°è®¡ç¬¬å››ä»£å°±å°†åœ¨ 2025 å¹´å‘å¸ƒå§ï¼Ÿçœ‹æ¥è¿™ç¯‡åšå®¢å®åœ¨æ˜¯æ‹–å»¶ä¸å¾—äº†ï¼
`ï¼ˆåˆï¼šé•¿ä¹…ä»¥æ¥æˆ‘æ€»è®¡åˆ’å¼€è®¾â€œNLP ç»å…¸è®ºæ–‡â€ä¸“åŒºï¼Œæ•´ç†è‡ª 2017 å¹´ä»¥æ¥â€œé‡ç‚¹æ–‡â€ï¼Œä¸å¦¨å°±ä»¥æ­¤ç¯‡ä½œå§‹å§ï¼ï¼‰`

## 2023 åˆ° 2024 å¹´ï¼šä»æ— åˆ°æœ‰ï¼Œç”±å¼±åŠå¼º

2023 åˆ° 2024 å¹´ï¼ŒmetaAI å…ˆåå‘å¸ƒ LLaMA1 åˆ° LLaMA3 çš„è®ºæ–‡ã€‚LLaMA ç³»åˆ—ä»æ— åˆ°æœ‰ã€ç”±å¼±åŠå¼ºï¼ŒæˆåŠŸè·»èº«å¤§è¯­è¨€æ¨¡å‹å…ˆé”‹å†›ä¹‹ä¸­ã€‚2023 ä¹Ÿç”±æ­¤å¯ä»¥ç§°ä½œ **LLaMA å…ƒå¹´**ã€‚

- 2023.2.27  ã€ŠLLaMAï¼šå¼€æ”¾é«˜æ•ˆçš„è¯­è¨€æ¨¡å‹ç³»åˆ—ã€‹ 
- 2023.7.19  ã€ŠLLaMA2ï¼šå¼€æ”¾ä¸”ç»è¿‡å¾®è°ƒçš„èŠå¤©æ¨¡å‹ã€‹
- 2024.11.23 ã€ŠLLaMA3 ç³»åˆ—æ¨¡å‹ã€‹

<table><thead>
    <tr><th rowspan="2">ç‰ˆæœ¬</th><th colspan="4" align="center">æ¨¡å‹ç»“æ„</th><th colspan="3" align="center">è®­ç»ƒæ•°æ®</th></tr>
    <tr><th>è§„èŒƒåŒ–</th><th>æ¿€æ´»å‡½æ•°</th><th>ä½ç½®ç¼–ç </th><th>GQA</th><th>Tokens</th><th>ä¸Šä¸‹æ–‡é•¿åº¦</th><th>Vocab Size</th></tr>
</thead><tbody>
    <tr><th>LLaMA1</th><th>RMSNorm</th><th>SwiGLU</th><th>RoPE</th><th>âœ—</th><th>1.4T</th><th>2K</th><th>32K</th></tr>
    <tr><th>LLaMA2</th><th>RMSNorm</th><th>SwiGLU</th><th>RoPE</th><th>âœ“</th><th>2.0T</th><th>4K</th><th>32K</th></tr>
    <tr><th>LLaMA3</th><th>RMSNorm</th><th>SiLU</th><th>RoPE</th><th>âœ“</th><th>15.0T</th><th>8K</th><th>128K</th></tr>
</tbody></table>

åœ¨æ¨¡å‹ç»“æ„ä¸Šï¼ŒLLaMA è‡ª 1 ä»£è‡³ 3 ä»£æ€»ä½“æ”¹åŠ¨è¾ƒå°ï¼Œå…¶ä¸­æ¯”è¾ƒå…³é”®çš„æŠ€æœ¯æ˜¯ï¼š**RMSNorm**ã€**RoPE** å’Œ **GQA**ã€‚**LLaMA çš„è¿­ä»£æ›´æ–°ä¸»è¦å¾—åŠ›äº metaAI ä¸æ–­æ‰©å……çš„ä¼˜è´¨è¯­æ–™åº“ï¼š**

- è‡ª 1 ä»£åˆ° 3 ä»£ï¼Œè¯­æ–™åº“çš„æ€» Token é‡ä» 1.4T ä¸Šå‡è‡³ 15Tï¼›
- è¯æ±‡è¡¨å¤§å°ä¹Ÿä»æœ€åˆçš„ 32K æ‰©å……è‡³ 128Kï¼›
- é¢„è®­ç»ƒçš„ä¸Šä¸‹æ–‡é•¿åº¦ä» 2K å¢åŠ åˆ° 4Kï¼Œå†åˆ°ç°åœ¨çš„ 8Kã€‚

åœ¨æ¨¡å‹å‚æ•°é‡ä¸Šï¼Œä¸‰ä»£ LLaMA æ€»ä½“å‘ˆç°ä¸Šå‡è¶‹åŠ¿ï¼š

- LLaMA1 åˆ†åˆ«å…·æœ‰ 7Bã€13Bã€33Bã€65B ç­‰ç‰ˆæœ¬ï¼›
- LLaMA2 ä¸ 1 ä»£æ¯”å·®è·ä¸å¤§ï¼ŒåŒ…æ‹¬ 7Bã€13Bã€34Bã€70B ç­‰ï¼›
- LLaMA3 çš„å‚æ•°é‡åˆ™æ˜¾è‘—æå‡ï¼Œä¸»è¦æ˜¯ 8Bã€70B ç”šè‡³ 405B ç­‰ã€‚

## LLaMA æ˜¯å¦‚ä½•ä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶çš„ï¼Ÿ

å›åˆ°æˆ‘ä»¬çš„è¯é¢˜ä¸Šæ¥ï¼š**LLaMA æ˜¯å¦‚ä½•ä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶çš„ï¼Ÿ** äº‹å®ä¸Šï¼ŒLLaMA åœ¨æ¨¡å‹æ¶æ„ä¸Šå¤§ä½“ä»æ²¿ç”¨ _(Vanilla,2017)_ æå‡ºçš„ Transformerï¼Œè€Œè¿›è¡Œäº†è®¸å¤šå¾®å°çš„æ”¹åŠ¨ã€‚æˆ‘æ ¹æ®è‡ªèº«å¯¹åŸè®ºæ–‡çš„ç†è§£ï¼Œè®¤ä¸ºå…¶ä¸­æ¯”è¾ƒé‡è¦çš„ä¸‰ä¸ªæŠ€æœ¯æ˜¯ï¼š**RMSNorm**ã€**RoPE** å’Œ **GQA**ã€‚è¿™äº›æŠ€æœ¯æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿå®ƒä»¬ä¸ºä»€ä¹ˆèƒ½ä¼˜åŒ–æ³¨æ„åŠ›æœºåˆ¶ï¼Ÿæ¥ä¸‹æ¥å¯¹å…¶è¿›è¡Œè¯¦ç»†è®²è§£ã€‚

### RMSNormï¼šåœ¨ä¸ç‰ºç‰²æ¨¡å‹ç¨³å®šæ€§çš„åŒæ—¶é™ä½è®¡ç®—å¤æ‚åº¦

åŸå§‹çš„ Transformer ä½¿ç”¨çš„æ˜¯ **å±‚è§„èŒƒåŒ–** _(LayerNorm)_ ã€‚ä¹‹æ‰€ä»¥å¼•å…¥è§„èŒƒåŒ–ï¼Œæ˜¯å¸Œæœ›æ¨¡å‹ä¸­é—´å±‚çš„è¾“å…¥åˆ†å¸ƒå§‹ç»ˆä¿æŒç¨³å®šã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒå¯¹è¾“å…¥ $x$ï¼ˆå‡è®¾ $x = [s_{0}^{j}, s_{1}^{j}, ..., s_{N}^{j}]$ï¼Œ$s$ æ˜¯é•¿åº¦ä¸º $N$ çš„åºåˆ—ï¼Œæ¯ä¸ªè¯å‘é‡å–ç¬¬ $j$ ä¸ªç»´åº¦ï¼‰è¿›è¡Œå¦‚ä¸‹æ“ä½œï¼š

$$y = \frac{x - E[x]}{\sqrt{Var[x] + \epsilon}} * \gamma + \beta. \quad \text{å…¶ä¸­ï¼š} E[x] = \frac{1}{N} \sum_{i=1}^{N} x_i, \quad Var[x] = \frac{1}{N} \sum_{i=1}^{N} (x_i - E[x])^2$$

è€Œ RMSNormï¼Œæˆ–ç§° **å‡æ–¹æ ¹è§„èŒƒåŒ–** å°±æ˜¯ LayerNorm çš„å˜ä½“ï¼ŒRMSNorm çœå»äº†æ±‚å‡å€¼çš„è¿‡ç¨‹ï¼Œä¹Ÿæ²¡æœ‰äº†åç½® $\beta$ï¼š

$$y = \frac{x}{\sqrt{Mean(x^2) + \epsilon}} * \gamma. \quad \text{å…¶ä¸­ï¼š} Mean(x^2) = \frac{1}{N} \sum_{i=1}^{N} x_i^2$$

é¦–å…ˆï¼Œåœ¨è®¡ç®—ä¸Šï¼šRMSNorm ç›¸æ¯” LayerNorm æ›´ä¸ºç®€ä¾¿ã€‚å…¶æ¬¡ï¼Œåœ¨æ•ˆæœä¸Šï¼šå®¹æ˜“çœ‹å‡º RMSNorm å…·æœ‰å¯¹è¾“å…¥ç¼©æ”¾çš„ä¸å˜æ€§ï¼ˆ$y(ax) = y(x)$ï¼‰ï¼Œä¸€å®šç¨‹åº¦ä¸Šä¹Ÿèƒ½å¤Ÿç¨³å®šè¾“å…¥åˆ†å¸ƒã€‚æœ€åï¼ŒRMSNorm å¹¶ä¸ä¿è¯è¾“å‡ºçš„å‡å€¼ä¸º 0ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ€§è´¨å¯¹æ¨¡å‹çš„è®­ç»ƒå½±å“è¾ƒå°ã€‚

### RoPEï¼šä»¥ç®€ä¾¿æ–¹å¼æœ‰æ•ˆæ•æ‰ç›¸å¯¹ä½ç½®ä¿¡æ¯

LLaMA åœ¨æ¯ä¸ª Attention å±‚ä¸­åˆ†åˆ«å¯¹ $Q$ å’Œ $K$ è¿›è¡Œ **æ—‹è½¬ä½ç½®ç¼–ç ** _(RoPE, Rotary Postion Embedding)_ å…·ä½“æ¥è¯´ï¼Œæ˜¯åœ¨ $Q$ å’Œ $K$ ç‚¹ç§¯ä¹‹å‰å¯¹ $Q$ å’Œ $K$ åˆ†åˆ«ç¼–ç ã€‚ä»¥ä¸‹æ˜¯éƒ¨åˆ† metaAI å®˜æ–¹ç»™å‡ºçš„ä»£ç ï¼š

```python
class Attention(nn.Module):
    def forward(self, x, ...):
        bsz, seqlen, hidden_dim = x.shape
        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)

        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)
        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)
        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)

        # å¯¹ Q å’Œ K æ–½ç”¨æ—‹è½¬ä½ç½®ç¼–ç 
        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)
        
        ... # æ­¤å¤„çœç•¥éƒ¨åˆ†ä»£ç 

        # å¯¹ Q å’Œ K æ±‚ç‚¹ç§¯å¹¶ç¼©æ”¾
        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)
```

é‚£ä¹ˆï¼Œä»€ä¹ˆæ˜¯ **æ—‹è½¬ä½ç½®ç¼–ç ** ï¼ŸRoPE åŸè®ºæ–‡çš„è¯´æ³•æ˜¯ï¼šâ€œåœ¨RoPEä¸­ï¼Œæˆ‘ä»¬çš„å‡ºå‘ç‚¹å°±æ˜¯ **é€šè¿‡ç»å¯¹ä½ç½®ç¼–ç çš„æ–¹å¼å®ç°ç›¸å¯¹ä½ç½®ç¼–ç ** ã€‚â€ä¹Ÿå³ï¼Œæˆ‘ä»¬è€ƒè™‘ï¼š

- å‡è®¾æˆ‘ä»¬æœ‰ç¼–ç æ“ä½œ $f(Â·)$ï¼Œåˆ†åˆ«å¯¹ $Q$ çš„ç¬¬ $m$ ç»´å‘é‡ $q$ å’Œ $K$ çš„ç¬¬ $n$ ç»´å‘é‡ $k$ è¿›è¡Œä½ç½®ç¼–ç ï¼š
    - $q_m = f (q, m) \quad k_n = f (k, n)$
- é‚£ä¹ˆåœ¨ Attention ä¸­å¯¹ $Q$ å’Œ $K$ æ±‚ç‚¹ç§¯æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ› $q_m$ å’Œ $k_n$ çš„å†…ç§¯ç»“æœå°†å¸¦å…¥ $m-n$ è¿™ä¸ª **ç›¸å¯¹ä½ç½®ä¿¡æ¯** _(m-n å°†å½±å“å†…ç§¯ç»“æœ)_ ï¼š
    - $<f (q, m), f (k, n)> = g(q, k, m-n)$
- åŸè®ºæ–‡ç»è¿‡å¤å®å˜æ¢å¾—åˆ°äº†æ“ä½œ $f(Â·)$ çš„è§£ï¼š
    - $f(q, m) = q e^{i m \theta} = q \cdot (\cos m \theta+ i \sin m \theta)$. å…¶ä¸­ $i$ ä¸ºè™šæ•°å•ä½ï¼Œ$\theta$ ä¸ºç»™å®šè¶…å‚ã€‚
    - æ ¹æ®å¤æ•°ä¹˜æ³•çš„å‡ ä½•æ„ä¹‰ï¼Œè¯¥å˜æ¢å®é™…ä¸Šå¯¹åº”ç€å‘é‡çš„æ—‹è½¬ï¼ˆæˆ‘ä»¬å¯ä»¥æƒ³è±¡äºŒç»´å‘é‡ï¼‰ã€‚
- æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å°† $f(q, m)$ çš„å®Œæ•´å½¢å¼è¡¨ç°å¦‚ä¸‹ï¼ˆå‡è®¾ $q$ ä¸º $d$ ç»´å‘é‡ï¼‰ï¼š
    - å…¶ä¸­ï¼Œ$\theta_i = 10000^{-2i/d}$ï¼Œè¿™å¸¦æ¥ä¸€å®šçš„è¿œç¨‹è¡°å‡æ€§ã€‚
    - $\otimes$ æ˜¯é€ä½å¯¹åº”ç›¸ä¹˜ï¼Œå³Numpyã€Tensorflowç­‰è®¡ç®—æ¡†æ¶ä¸­çš„ $âˆ—$ è¿ç®—ã€‚
    - ä»è¿™ä¸ªå®ç°ä¹Ÿå¯ä»¥çœ‹åˆ°ï¼ŒRoPEå¯ä»¥è§†ä¸ºæ˜¯ä¹˜æ€§ä½ç½®ç¼–ç çš„å˜ä½“ã€‚

<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtable displaystyle="true"><mlabeledtr><mtd></mtd><mtd><mrow><mo>(</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><msub><mi>q</mi><mn>0</mn></msub></mtd></mtr><mtr><mtd><msub><mi>q</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><msub><mi>q</mi><mn>2</mn></msub></mtd></mtr><mtr><mtd><msub><mi>q</mi><mn>3</mn></msub></mtd></mtr><mtr><mtd><mo>â‹®</mo></mtd></mtr><mtr><mtd><msub><mi>q</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mo>âˆ’</mo><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>q</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>âŠ—</mo><mrow><mo>(</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mi>cos</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>0</mn></msub></mtd></mtr><mtr><mtd><mi>cos</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>0</mn></msub></mtd></mtr><mtr><mtd><mi>cos</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><mi>cos</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><mo>â‹®</mo></mtd></mtr><mtr><mtd><mi>cos</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>2</mn><mo>âˆ’</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mi>cos</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>2</mn><mo>âˆ’</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mo>âˆ’</mo><msub><mi>q</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><msub><mi>q</mi><mn>0</mn></msub></mtd></mtr><mtr><mtd><mo>âˆ’</mo><msub><mi>q</mi><mn>3</mn></msub></mtd></mtr><mtr><mtd><msub><mi>q</mi><mn>2</mn></msub></mtd></mtr><mtr><mtd><mo>â‹®</mo></mtd></mtr><mtr><mtd><mo>âˆ’</mo><msub><mi>q</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mo>âˆ’</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><msub><mi>q</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mo>âˆ’</mo><mn>2</mn></mrow></msub></mtd></mtr></mtable><mo>)</mo></mrow><mo>âŠ—</mo><mrow><mo>(</mo><mtable rowspacing="4pt" columnspacing="1em"><mtr><mtd><mi>sin</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>0</mn></msub></mtd></mtr><mtr><mtd><mi>sin</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>0</mn></msub></mtd></mtr><mtr><mtd><mi>sin</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><mi>sin</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mn>1</mn></msub></mtd></mtr><mtr><mtd><mo>â‹®</mo></mtd></mtr><mtr><mtd><mi>sin</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>2</mn><mo>âˆ’</mo><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd><mi>sin</mi><mo>â¡</mo><mi>m</mi><msub><mi>Î¸</mi><mrow class="MJX-TeXAtom-ORD"><mi>d</mi><mrow class="MJX-TeXAtom-ORD"><mo>/</mo></mrow><mn>2</mn><mo>âˆ’</mo><mn>1</mn></mrow></msub></mtd></mtr></mtable><mo>)</mo></mrow></mtd></mlabeledtr></mtable></math>

æœ€ååœ¨è¿™é‡Œè´´ä¸€ä»½ metaAI å®˜æ–¹å†™çš„ä»£ç ï¼Œä»¥ä¾¿æ›´åŠ ç›´è§‚åœ°çœ‹åˆ° RoPE æ“ä½œæ˜¯å¦‚ä½•å®ç°çš„ã€‚

```python
def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):
    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))
    t = torch.arange(end, device=freqs.device)  # type: ignore
    freqs = torch.outer(t, freqs).float()  # type: ignore
    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64
    return freqs_cis

def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):
    ndim = x.ndim
    assert 0 <= 1 < ndim
    assert freqs_cis.shape == (x.shape[1], x.shape[-1])
    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]
    return freqs_cis.view(*shape)

def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))
    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))
    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)
    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)
    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)
    return xq_out.type_as(xq), xk_out.type_as(xk)
```

### GQAï¼šå‡å°‘ KV-Cache å¤§å°ä»¥æå‡æ¨¡å‹æ¨ç†é€Ÿåº¦

#### å¼•å…¥ GQA å‰å…ˆç®€å•ä»‹ç»ä¸‹ KV-Cache

æé«˜å¤§æ¨¡å‹æ¨ç†é€Ÿåº¦çš„å¸¸ç”¨å…³é”®æŠ€æœ¯æ˜¯ **KV-Cache**ã€‚å¤§æ¨¡å‹ä»¥ **è‡ªå›å½’** _(auto regressive)_ çš„æ–¹å¼æ¨ç†ï¼Œé¢„æµ‹ä¸‹ä¸ª token æ—¶ï¼Œæ€»æ˜¯åŸºäºä¹‹å‰å·²ç»ç”Ÿæˆçš„åºåˆ—ã€‚ä»ä»£ç çš„è§’åº¦æ¥ç†è§£æ˜¯è¿™æ ·çš„ï¼š

```python
inputs = "è¿™æ˜¯åˆå§‹çš„è¾“å…¥åºåˆ—"

while not stop:
    # æ ¹æ®ä¹‹å‰çš„åºåˆ—é¢„æµ‹ä¸‹ä¸ª token
    next_token = model(inputs)

    # å¦‚æœä¸‹ä¸ª token æ˜¯ä¼‘æ­¢ç¬¦ï¼Œé€€å‡º
    # å¦åˆ™ï¼Œå°† token åŠ å…¥åºåˆ—è¿›è¡Œä¸‹æ¬¡é¢„æµ‹
    if next_token == '[SEP]':
        stop = True
    else:
        inputs += next_token

outputs = inputs
```

æ˜¾ç„¶ï¼Œéšç€è¾“å…¥åºåˆ—è¶Šæ¥è¶Šé•¿ï¼Œæ¯æ¬¡éƒ½é‡æ–°è®¡ç®—æ‰€æœ‰ token æ³¨æ„åŠ›å€¼çš„ä¼ ç»Ÿæ–¹æ³•æ˜¾å¾—éå¸¸ä½æ•ˆã€‚é’ˆå¯¹è¯¥é—®é¢˜ï¼ŒKV-Cache é‡‡ç”¨ **ç©ºé—´æ¢æ—¶é—´** çš„æ–¹æ³•ï¼šåœ¨è‡ªå›å½’è¿‡ç¨‹ä¸­ï¼Œå¼€è¾Ÿç©ºé—´å°†æ¯æ¬¡è®¡ç®—çš„ $K$ å’Œ $V$ ç¼“å­˜èµ·æ¥ï¼Œè¿™æ ·åœ¨å¤„ç†æ–°åºåˆ—æ—¶åªéœ€ä»ç¼“å­˜ä¸­è¯»å–ä¹‹å‰çš„ $K$ å’Œ $V$ï¼Œæ— éœ€é‡å¤è®¡ç®—ã€‚LLaMA ä¸­çš„ä»£ç å®ç°å¦‚ä¸‹ï¼š

```python
class Attention(nn.Module):
    def __init__(self, ...):
        super().__init__()
        ... # æ­¤å¤„çœç•¥éƒ¨åˆ†ä»£ç 

        # å¼€è¾Ÿ cache_k ç”¨äºç¼“å­˜ k
        self.cache_k = torch.zeros(
            (
                args.max_batch_size,
                args.max_seq_len,
                self.n_local_kv_heads,
                self.head_dim,
            )
        ).cuda()
        # å¼€è¾Ÿ cache_v ç”¨äºç¼“å­˜ v
        self.cache_v = torch.zeros(
            (
                args.max_batch_size,
                args.max_seq_len,
                self.n_local_kv_heads,
                self.head_dim,
            )
        ).cuda()

    def forward(self, x, ...):
        ... # æ­¤å¤„çœç•¥éƒ¨åˆ†ä»£ç 

        # å°†ç¼“å­˜ç½®äº xq æ‰€åœ¨çš„è®¡ç®—å•å…ƒï¼ˆCPU æˆ– CUDAï¼‰
        self.cache_k = self.cache_k.to(xq)
        self.cache_v = self.cache_v.to(xq)

        # å°†å½“å‰è®¡ç®—å‡ºçš„ K ä¸ V ç¼“å­˜èµ·æ¥
        # ç¼“å­˜ä½ç½®æ˜¯ä» start_pos åˆ° start_pos + seqlen
        # start_pos æ˜¯ä¸Šæ¬¡ç¼“å­˜åçš„åºåˆ—é•¿åº¦
        # seqlen æ˜¯æ­¤æ¬¡æ–°å¢çš„å­åºåˆ—é•¿åº¦ï¼ŒKV-Cache å¹¶éé€å­—ç¼“å­˜çš„
        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk
        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv

        # è·å–ç¼“å­˜çš„ K ä¸ Vï¼Œç”¨äºä¹‹åçš„è®¡ç®—
        keys = self.cache_k[:bsz, : start_pos + seqlen]
        values = self.cache_v[:bsz, : start_pos + seqlen]
```

åœ¨äº†è§£äº† KV-Cache åï¼Œæˆ‘ä»¬ä¸ç¦ä¼šåæ€ï¼šæ—¢ç„¶ $K$ å’Œ $V$ èƒ½å¤Ÿç¼“å­˜ï¼Œé‚£ä¸ºä»€ä¹ˆä¸ç¼“å­˜ $Q$ å‘¢ï¼Ÿç­”æ¡ˆæ˜¯ï¼šä¸éœ€è¦ï¼ä¸ BERT ä¸åŒï¼ŒLLaMAã€GPT ç­‰å¤§è¯­è¨€æ¨¡å‹éƒ½æ˜¯ Decoder-Only æ¶æ„ï¼Œé‡‡ç”¨ **å•å‘æ³¨æ„åŠ›æœºåˆ¶**ã€‚ç”±äºä½¿ç”¨äº†æ³¨æ„åŠ›æ©ç ï¼Œä½ç½®é å token çš„ $K$ å€¼å°†æ— æ³•ä¸ä½ç½®é å‰ token çš„ $Q$ å€¼æ±‚å†…ç§¯ã€‚å› æ­¤ï¼Œç¼“å­˜å†å² token çš„ $Q$ å€¼æ˜¯å®Œå…¨æ²¡æœ‰å¿…è¦çš„ã€‚

#### GQAï¼šç”¨åˆ†ç»„çš„æ–¹å¼å‡å°‘ KV å¯¹çš„æ•°é‡

ç„¶è€Œï¼Œå¼•å…¥ KV-Cahe æ„å‘³ç€éœ€è¦å¼€è¾Ÿå¤§é‡çš„ç¼“å­˜ç©ºé—´ã€‚åœ¨ **å¤šå¤´æ³¨æ„åŠ›** _(MHA)_ ä¸­ï¼Œæ‰€éœ€å¼€è¾Ÿçš„ç¼“å­˜ç©ºé—´å¤§å°å¯æŒ‰ç…§å¦‚ä¸‹å…¬å¼è®¡ç®—ï¼š

$$N \times B \times L \times H \times D$$

- $N$ æŒ‡ Transformer å—çš„æ•°é‡ã€‚ä»¥ LLaMA2 ä¸ºä¾‹ï¼Œå®ƒå…±åŒ…å« 32 ä¸ªã€‚
- $B$ æŒ‡è¾“å…¥æ•°æ®çš„æ‰¹é‡å¤§å°ã€‚è¿™é‡Œæˆ‘ä»¬å‡è®¾æ˜¯ 16ã€‚
- $L$ ä¸ºè¾“å…¥å¥å­çš„é•¿åº¦ã€‚ä¸ºä¾¿äºè®¡ç®—ï¼Œæˆ‘ä»¬å–æœ€å¤§é•¿åº¦ä¸º 1024ã€‚
- $H$ æ˜¯æ³¨æ„åŠ›å¤´çš„ä¸ªæ•°ã€‚å‡è®¾æ˜¯ 32ï¼Œä¸åŸè®ºæ–‡ä¿æŒä¸€è‡´ã€‚
- $D$ æ˜¯éšè—å±‚çš„ç»´åº¦æ•°ã€‚å®ƒåœ¨ LLaMA-7B ä¸­è¢«è®¾ä¸º 4096ã€‚

æ ¹æ®å…¬å¼ï¼Œæˆ‘ä»¬å¾—å‡ºä¸ºäº†ç¼“å­˜ KV æ‰€éœ€çš„ç©ºé—´å¤§å°ä¸º $32 * 16 * 1024 * 32 * 4096 = 2^{36}$ ä»½æµ®ç‚¹æ•°æ‰€éœ€çš„ç©ºé—´ã€‚è‹¥æˆ‘ä»¬ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•° float16 ç±»å‹å­˜å‚¨ï¼Œå°±éœ€è¦ $2^{36} * 2 \text{Byte} = 128 \text{GB}$ å¤§å°çš„å­˜å‚¨ç©ºé—´ï¼å‚ç…§ LLaMA1 è®ºæ–‡ä¸­ç»™å‡ºçš„ç¡¬ä»¶è®¾ç½®ï¼Œè¿™è¿œè¿œåœ°è¶…å‡ºäº†ä»–ä»¬æ‰€æä¾›çš„ RAM 80GB çš„å®¹é‡ã€‚

ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¿…é¡»ä¼˜åŒ–ç®—æ³•ã€‚ç”±æ­¤ï¼Œä¾¿å¼•å‡ºäº† LLaMA è‡ª 2 ä»£å¼€å§‹æ‰€ä½¿ç”¨çš„ **GQA** _(Group Query Attention)_ ã€‚ä»¥ä¸‹æ‘˜è‡ª GQA çš„åŸè®ºæ–‡çš„å›¾ç‰‡ç®€å•æ˜äº†åœ°è¯´æ˜äº†ä»€ä¹ˆæ˜¯ GQAã€‚

![MHA GQA MQA](https://cdn.jsdelivr.net/gh/lazypool/blog-pics/blogpost/the2025/0109_mha_gqa_mqa.png)

å¦‚å›¾æ‰€ç¤ºï¼šåœ¨ **å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå·¦ï¼ŒMHAï¼‰** ä¸­ï¼Œæ¯ä¸ªæ³¨æ„åŠ›æŸ¥è¯¢ Q éƒ½æœ‰å„è‡ªå¯¹åº”çš„ KV å¯¹ï¼Œè¿™å¯¼è‡´ç¼“å­˜ KV æ‰€éœ€çš„ç©ºé—´æå¤§ã€‚æœ€æç«¯çš„æƒ…å†µä¸‹ï¼Œå¦‚ **å¤šæŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå³ï¼ŒMQAï¼‰**ï¼Œæ‰€æœ‰çš„æŸ¥è¯¢ Q å…±äº«å”¯ä¸€çš„ KV å¯¹ï¼Œè™½æœ€å¤§ç¨‹åº¦åœ°å‡å°‘äº†æ‰€éœ€çš„ç¼“å­˜ç©ºé—´ï¼Œä½†å¸¦æ¥äº†ç²¾åº¦çš„ä¸‹é™ã€‚è€Œ **åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼ˆä¸­é—´ï¼ŒGQAï¼‰**ï¼Œåœ¨ç²¾åº¦å’Œè®¡ç®—ä¹‹é—´æŠ˜ä¸­ï¼šå°†å„æŸ¥è¯¢ Q åˆ†ç»„ï¼ŒåŒç»„æŸ¥è¯¢å…±äº«ä¸€ä¸ª KV å¯¹ï¼Œåœ¨ä¿è¯ç²¾åº¦çš„åŒæ—¶ä¸€å®šç¨‹åº¦åœ°å‡å°‘ç¼“å­˜ç©ºé—´ã€‚

æˆ‘ä»¬å¯ä»¥ç¨åšè®¡ç®—ï¼šè‹¥æˆ‘ä»¬å°†åŸæœ‰çš„ 32 ä¸ªæ³¨æ„åŠ›å¤´åˆ†æˆ 8 ç»„ï¼Œæ¯ç»„ 4 ä¸ªæŸ¥è¯¢ã€‚é‚£ä¹ˆå°±ä»…ä¼šæœ‰ 8 ä¸ª KV å¯¹ï¼Œæ‰€éœ€çš„ç¼“å­˜ç©ºé—´å°±å˜ä¸ºäº†åŸæ¥çš„å››åˆ†ä¹‹ä¸€ï¼ˆ128GB -> 32GBï¼‰ã€‚ç”±æ­¤ï¼Œæ¨¡å‹æ¨ç†æ€§èƒ½å¾—åˆ°æå‡ï¼Œæˆ‘ä»¬å°±å¯ä»¥å–‚ç»™æ¨¡å‹æ›´å¤šå’Œæ›´é•¿çš„å¥å­ï¼Œæˆ–è€…æ­å»ºæ›´æ·±çš„ç½‘ç»œå’Œè®¾ç½®æ›´å¤§çš„éšè—å±‚ç»´åº¦ã€‚

metaAI åœ¨ä»£ç ä¸­çš„å…·ä½“å®ç°æ–¹å¼ä¸ºï¼šé™åˆ¶ KV å¤´çš„æ•°ç›®å°äº Q å¤´çš„æ•°ç›®ï¼Œåœ¨è®¡ç®—çš„æ—¶å€™å¤åˆ¶ KV å¤´ä»¥ä½¿å…¶èƒ½å¤Ÿä¸ Q çš„å¤´å¯¹åº”ï¼Œåœ¨ç¼“å­˜çš„æ—¶å€™ä»…ç¼“å­˜ä¸é‡å¤çš„ KV å¯¹ã€‚ä»£ç å¦‚ä¸‹ï¼š

```python
# é‡å¤ KVï¼šx æ˜¯è¦é‡å¤çš„å¯¹è±¡ï¼ˆK æˆ– Vï¼‰
# n_rep æ˜¯é‡å¤çš„æ¬¡æ•°ï¼Œå®ƒç­‰äº Q çš„å¤´é™¤ä»¥ KV çš„å¤´
def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:
    """torch.repeat_interleave(x, dim=2, repeats=n_rep)"""
    bs, slen, n_kv_heads, head_dim = x.shape
    if n_rep == 1:
        return x # è§„å®šé‡å¤ 1 æ¬¡ç­‰äºä¸é‡å¤
    return (
        x[:, :, :, None, :] # é‡å¤åç¬¬ 3 ä¸ªç»´åº¦å˜æˆ n_rep * KV çš„å¤´æ•°
        .expand(bs, slen, n_kv_heads, n_rep, head_dim)
        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)
    )

class Attention(nn.Module):
    def forward(self, x, ...):
        ... # æ­¤å¤„çœç•¥éƒ¨åˆ†ä»£ç 

        keys = self.cache_k[:bsz, : start_pos + seqlen]
        values = self.cache_v[:bsz, : start_pos + seqlen]

        # é‡å¤ KV çš„å¤´ä»¥ä½¿ä¹‹ä¸ Q çš„å¤´å¯¹åº”
        keys = repeat_kv(keys, self.n_rep)
        values = repeat_kv(values, self.n_rep)

        ## ä»¥ä¸‹ä»£ç æ˜¯æ³¨æ„åŠ›æœºåˆ¶çš„å…·ä½“è®¡ç®—è¿‡ç¨‹
        # B æ‰¹é‡å¤§å°    L åºåˆ—é•¿åº¦
        # H æ³¨æ„åŠ›å¤´æ•°  D éšè—å±‚ç»´åº¦æ•°
        # C å·²ç¼“å­˜çš„åºåˆ—é•¿åº¦
        xq = xq.transpose(1, 2)  # [B, L, H, D] -> [B, H, L, D]
        keys = keys.transpose(1, 2) # [B, C + L, H, D] -> [B, H, C + L, D]
        values = values.transpose(1, 2) # [B, C + L, H, D] -> [B, H, C + L, D]
        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)
        if mask is not None:
            scores = scores + mask  # [B, H, L, C + L]
        scores = F.softmax(scores.float(), dim=-1).type_as(xq)
        output = torch.matmul(scores, values) # [B, H, L, D]
        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)
        return self.wo(output)
```

### CodeWorkï¼šå›é¡¾ä¸æ€»ç»“ï¼Œå°è¯•é˜…è¯»å®Œæ•´ä»£ç 

åœ¨ä¹‹å‰å¯¹ RoPEã€KV-Cacheã€GQA çš„ä»‹ç»ä¸­ï¼Œæˆ‘ä»¬äº‹å®ä¸Šå·²ç»å°† LLaMA ä¸­ Attention æ¨¡å—çš„ forward() å‡½æ•°éƒ¨åˆ†çš„å…¨éƒ¨ä»£ç å±•ç¤ºå‡ºæ¥äº†ã€‚ç°åœ¨è´´ä¸€ä»½å®Œæ•´çš„ä»£ç åœ¨è¿™é‡Œï¼Œå¯ä»¥è¯•ç€åœ¨æ— æ³¨é‡Šçš„æ¡ä»¶ä¸‹ç†è§£ä»£ç åšäº†ä»€ä¹ˆã€‚å¦‚æœæƒ³çœ‹æºç ï¼Œä¹Ÿå¯ä»¥è®¿é—® [metaAI å®˜æ–¹çš„ä»£ç ](https://github.com/meta-llama/llama/blob/main/llama/model.py)ã€‚

```python
class Attention(nn.Module):
    def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):
        bsz, seqlen, _ = x.shape
        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)

        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)
        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)
        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)

        xq, xk = apply_rotary_emb(xq, xk, freqs_cis=freqs_cis)

        self.cache_k = self.cache_k.to(xq)
        self.cache_v = self.cache_v.to(xq)

        self.cache_k[:bsz, start_pos : start_pos + seqlen] = xk
        self.cache_v[:bsz, start_pos : start_pos + seqlen] = xv

        keys = self.cache_k[:bsz, : start_pos + seqlen]
        values = self.cache_v[:bsz, : start_pos + seqlen]

        keys = repeat_kv(keys, self.n_rep)
        values = repeat_kv(values, self.n_rep)

        xq = xq.transpose(1, 2)
        keys = keys.transpose(1, 2)
        values = values.transpose(1, 2)
        scores = torch.matmul(xq, keys.transpose(2, 3)) / math.sqrt(self.head_dim)
        if mask is not None:
            scores = scores + mask
        scores = F.softmax(scores.float(), dim=-1).type_as(xq)
        output = torch.matmul(scores, values)
        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)
        return self.wo(output)
```

## å¦‚ä½•è®­ç»ƒä¸€ä¸ªå¯¹è¯æœºå™¨äººï¼šLLaMA2 æ˜¯å¦‚ä½•åšçš„ï¼Ÿ

// to be continued

## å¤šæ¨¡æ€ï¼Ÿæ¥çœ‹çœ‹ LLaMA3 çš„è¡¨ç°ï¼

// to be continued
