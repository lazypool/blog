---
layout: post
title: Kafka 技术在 B 站 📺 的探索与实现
categories:
  - 📢 技术杂谈
tags: [Kafka, B站, 大数据技术]
index_img: https://cdn.jsdelivr.net/gh/lazypool/blog-pics/animals/00014.jpg
date: 2025-03-27 20:13:19
---

# Kafka 技术在 B 站的探索与实现

Apache Kafka 是一个**分布式数据流处理平台，可以实时发布、订阅、存储和处理数据流**。它旨在处理多种来源的数据流，并将它们交付给多个消费者。简而言之，它可以移动大量数据，不仅是从 A 点移到 B 点，而是能从 A 到 Z 的多个点移到任何您想要的位置，并且可以同时进行。

> Apache Kafka 可以取代传统的企业级消息传递系统。它最初是 Linkedin 为处理每天 1.4 万亿条消息而开发的一个内部系统，现已成为应用于各式各样企业需求的开源数据流处理解决方案。

## 背景、挑战、痛点

B 站是当今国内最火的 AGC 网站，其用户群体以年轻人为主。B 站拥有 1000+ 台 Kafka 机器，组成了 20 多个集群。每天，这些 Kafka 端点都会在公司的各个部门之间上报、暂存、分发各种数据，输入 PB 级数据，输出数十 PB。随着集群规模的扩张，B站遇到了越来越多的挑战。

![B 站 Kafka 数据流向](kafka-stream-direction.avif)

- 客户端读写方式多样、难以检测，难以协调集群稳定性和资源利用率。同时，过密的读写操作引发大量的磁盘 I/O，影响用户读写效率。
- 集群多业务共用，核心业务和普通业务互相影响，出现问题时受波及的地方过广。
- 开源版本的限速粒度很粗，不灵活，难以实时根据磁盘状态进行对应调整。
- Kafka 以集群稳定性著称，但这是以繁琐的上下线流程为代价的，导致效率低下。
- 开源版本在分配 Partion 时仅考虑机器 Partion 数量，不考虑磁盘流量负载情况，也不考虑 Topic 之间的差异，导致集群中机器间、磁盘间负载不均衡。
- 随着公司业务不断扩大，一套 IDC 不足以支撑整个公司的服务，需要控制并协调多个 IDC。
- Kafka 只有一个工作线程池，慢请求可能导致线程池阻塞，影响其他请求处理效率。

## Guardian - Kafka federation cluster controller

为了应对这些挑战，哔哩哔哩开发了一套自动化治理系统，有效地解决目前面临的问题。Guardian 是一套自研的 Kafka federation cluster controller。该服务通过 Raft 保证了高可用和一致性，并支持从 Kafka Server 端收集各类数据进行计算和分析，执行治理计划。包含以下功能：

&emsp;1. 元数据管理与集群。 2. 元数据管理与存储。 3. uuid(topic, segmentID) 的分配。 4. 收集集群信息进行调度。 5. 多租户管理与 label 隔离。 6. 故障预警与自愈。

![Guardian：Kafka 联邦集群控制层](kafka-guardian.avif)

> 基于 JMX 协议采集 Metrics 的性能非常差，这是因为 jmx 协议一个请求只能获取一个 mbean。随着 metric 的加强，可能达到万级别，此时 cpu 消耗会占 20% 甚至更高。Kafka Reporter 为基于 GRPC，http 协议的内置 Metric 上报服务，只需要一个 rpc 即可拉取全部监控数据。

## 集群层面治理

### Partition 级别限速保护

Kafka 是一个 I/O 密集型的服务，用户行为不可预测且多变。当用户读取最新数据时，能够从 Page Cache 中高效快速获取，但如果需要从磁盘中读取数据，那么就要考虑如何控制磁盘 I/O 和磁盘资源的使用，以便为用户提供最大的吞吐量。开源的限速方案存在的问题是粗粒度，比如限制某 ClientId 的读速度为 5MB/s，那么此 Client 在某台机器下读取所有订阅的 Partition 的速度的总和被限制到 5MB/s 左右，无法精确限制到 Partition。

为了让磁盘合理且更充分地利用，需要为 Kafka 新增 Partition 粒度的限速逻辑。**通过管控系统实时监测每个磁盘的 ioutil 和 Latency 等关键指标，一旦发现某块磁盘超过了设定的阈值，就会判断该磁盘的健康度下降，需要进行优化处理。**此时，尝试对该磁盘下的 io 操作进行限速，使该磁盘的 ioutil 和 Latency 恢复到合理水平。为此，B 站团队设计了一种估算算法：

1. 用**可用内存大小除以磁盘读写的速率和**，粗略估算出一段数据能在 PageCache 里面存在的时间 T。
2. 使用 Partition 的 MessageInRate 乘以 T 估算出此 Partition 能在 PageCache 里面缓存数据条数。
3. 然后计算 **Partition LEO - MessageInRate * T**。若其大于要拉取数据的 Offset，那么认为此数据是实际读磁盘数据。

![Partition 级别限速保护机制](kafka-partion-speed-restriction.avif)

- Guardian 基于集群监控数据进行集群磁盘的健康度检查，根据每一个分区的监控数据进行根因分析，根据分析结果及时进行限速调整。
- 磁盘 IO 相关行为分为六种：**用户读/写磁盘**，**主从同步读/写磁盘**和**磁盘间迁移读/写磁盘**。
- 异常行为：超过预期的写磁盘，任何读磁盘。
- 将所有异常行为排序为 **异常行为队列**。异常行为队列排序方式为当前流量大到小排优先级。
- 在实际使用中，根据集群状况实时进行自动限速保护的功能对Kafka集群的稳定性做出了很大贡献。

### 自动 Partition 均衡

为了解决开源 Kafka 的负载分配不均匀导致的磁盘热点问题，哔哩哔哩开发了一种基于磁盘指标、集群 Topic 分布情况和每个 Partition 流量指标的 Partition 自动均衡迁移计划功能。

![Partition 负载均衡](kafka-partion-load-balance.avif)

1. **负载分析和迁移计划生成**：根据采集到的数据，识别高负载机器及需要进行负载均衡的待迁移 Partition。生成迁移计划时，考虑目标磁盘的流量负载，按磁盘历史流量负载的中位数排序，选择负载最小的磁盘作为迁移目标。
2. **增量提交**：在集群执行均衡迁移计划时，不同 Partition 所承载的流量不同，所在的机器负载不同，搬迁所需要的时间也会不同。采取增量提交均衡任务，让耗时较长的任务不会阻塞其他任务，保持高效执行。
3. **动态调整搬迁速度**：根据集群内机器的负载动态调整搬迁的速度，让搬迁任务不会影响到集群的稳定性和用户的使用。
4. **多并发搬迁**：支持不同集群不同 Partition 并发的执行搬迁计划，并可控制并发度。
5. **Partition 预分配**：新建 Topic 时，根据当前磁盘负载和该 Topic 的预期估值流量进行计算，生成该 Topic 所有 Partition 的预分配计划。
6. **Leader 均衡**：为了避免 Partition Leader 机器严重不均衡造成的机器热点问题，自动生成均衡计划进行 Partition Leader 均衡。
7. **异常熔断**：当某个节点异常，搬迁计划无法顺利执行完成时或当流量上涨需要进行 Partition 扩容时，自动取消当前所影响的搬迁计划。

### 多租户资源隔离管理

### 多机房管理

### 请求队列拆分

### Tired-Storage

### Kafka 审计功能

## 运维层面治理

### 集群平滑发布

### 未来展望
